{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a221bd65",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad446f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification Methods\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from yellowbrick.classifier import ClassificationReport \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#Tools\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from scipy.sparse import csr_matrix \n",
    "import string \n",
    "import time as tm\n",
    "import spacy \n",
    "import os\n",
    "sns.set(style='whitegrid',\n",
    "        rc={'lines.linewidth': 2.5,\n",
    "        'figure.figsize': (10, 8),\n",
    "        'text.usetex': False,\n",
    "        })\n",
    "%matplotlib inline\n",
    "\n",
    "# Hyperparameter tune\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Feature importance\n",
    "from yellowbrick.model_selection import FeatureImportances\n",
    "from yellowbrick.features import PCADecomposition\n",
    "from yellowbrick.features import RadViz \n",
    "from yellowbrick.features import Manifold\n",
    "\n",
    "#mpl.rcParams[\"figure.figsize\"] = (9,6)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7e1df9",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521e558f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_metrics(X_train,X_test,y_train,y_test,CV=True):    \n",
    "    def metrics(model):\n",
    "        print(\"\\nHold-Out in process...\")\n",
    "        start_time = tm.time()\n",
    "        model.fit(X_train, y_train) \n",
    "        TIME = tm.time() - start_time \n",
    "        print(\"Time, Training: {0:.4f} [seconds]\".format(TIME))\n",
    "        start_time = tm.time()\n",
    "        y_pred = model.predict(X_test)\n",
    "        TIME = tm.time() - start_time \n",
    "        print(\"Time, Prediction: {0:.4f} [seconds]\".format(TIME))\n",
    "        \n",
    "        accuracy_s  = accuracy_score(y_test,y_pred) \n",
    "        print('accuracy_score: {0:.4f}'.format(accuracy_s))\n",
    "        f1_s        = f1_score(y_test,y_pred,average='weighted')\n",
    "        print('f1_score: {0:.4f}'.format(f1_s))\n",
    "        recall_s    = recall_score(y_test,y_pred,average='weighted')\n",
    "        print('recall_score: {0:.4f}'.format(recall_s))\n",
    "        precision_s = precision_score(y_test,y_pred,average='weighted')\n",
    "        print('precision_score: {0:.4f}'.format(precision_s))\n",
    "        \n",
    "        if type(list(np.unique(np.array(y_train)))[0]).__name__ == 'str': #If the classes are categorical with string names\n",
    "            le           = LabelEncoder() \n",
    "            le.fit(list(np.unique(np.array(y_train)))) \n",
    "            y_test_coded = le.transform(y_test) \n",
    "            y_pred_coded = le.transform(y_pred) \n",
    "            mse_s        = MSE(y_test_coded,y_pred_coded)\n",
    "            print('MSE: {0:.4f}'.format(mse_s))\n",
    "        else:\n",
    "            mse_s        = MSE(y_test,y_pred)\n",
    "            print('MSE: {0:.4f}'.format(mse_s))\n",
    "        \n",
    "        if len(list(np.unique(np.array(y_train)))) > 2: #For multiclass classification, more than 2 classes\n",
    "            y_pred_proba = model.predict_proba(X_test)[:]\n",
    "            roc_s        = roc_auc_score(y_test, y_pred_proba, multi_class='ovo', average='weighted')\n",
    "            print('ROC_AUC: {0:.4f}'.format(roc_s))            \n",
    "        else:\n",
    "            y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "            roc_s        = roc_auc_score(y_test, y_pred_proba, multi_class='ovo', average='weighted')\n",
    "            print('ROC_AUC: {0:.4f}'.format(roc_s))\n",
    "        \n",
    "        ck_s         = cohen_kappa_score(y_test,y_pred)\n",
    "        print('CK: {0:.4f}'.format(ck_s))\n",
    "        \n",
    "        if CV == True:\n",
    "            print('\\nCross-Validation in process...')\n",
    "            start_time = tm.time() \n",
    "            kfold = model_selection.KFold(n_splits=10)\n",
    "            y_CV = np.concatenate((y_train,y_test))\n",
    "            if \"GaussianNB\" in str(name) or \"LinearDiscriminantAnalysis\" in str(name) or \"QuadraticDiscriminantAnalysis\" in str(name):\n",
    "                X_CV = np.concatenate((X_train,X_test))\n",
    "                cv_results = np.array(model_selection.cross_val_score(model, X_CV, y_CV, cv=kfold, scoring='accuracy', n_jobs=-3))\n",
    "            else:\n",
    "                X_CV = np.concatenate((X_train.toarray(),X_test.toarray()))\n",
    "                X_CV = csr_matrix(X_CV)\n",
    "                cv_results = np.array(model_selection.cross_val_score(model, X_CV, y_CV, cv=kfold, scoring='accuracy', n_jobs=-3))\n",
    "\n",
    "            cv_results = cv_results[np.logical_not(np.isnan(cv_results))] \n",
    "            TIME = tm.time() - start_time \n",
    "            print(\"Time, CV: {0:.4f} [seconds]\".format(TIME))\n",
    "            print('CV: {0:.4f} {1:.4f}'.format(cv_results.mean(),cv_results.std()))\n",
    "\n",
    "    for name in classifiers:\n",
    "        print (\"---------------------------------------------------------------------------------\\n\") \n",
    "        print(str(name))\n",
    "        if \"GaussianNB\" in str(name) or \"LinearDiscriminantAnalysis\" in str(name) or \"QuadraticDiscriminantAnalysis\" in str(name):\n",
    "            X_train=csr_matrix(X_train) \n",
    "            X_test =csr_matrix(X_test) \n",
    "            X_train=X_train.toarray() \n",
    "            X_test=X_test.toarray() \n",
    "        else:\n",
    "            X_train=csr_matrix(X_train)\n",
    "            X_test=csr_matrix(X_test)\n",
    "            \n",
    "        metrics(name)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fb3778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "def CR_viz(x,y):\n",
    "    ax = plt.figure(figsize=(x,y)) \n",
    "    visualizer = ClassificationReport(model_selected, classes=classes, support=True,  \n",
    "                                      cmap='Blues', title=\"Classification Report - \"+model_name)\n",
    "    visualizer.fit(X_train, y_train)   \n",
    "    visualizer.score(X_test, y_test)      \n",
    "    visualizer.poof()\n",
    "    ax.show()\n",
    "    ax.savefig(path_figures+\"/\"+model_name+\"_CR\"+\".pdf\", bbox_inches = \"tight\") \n",
    "\n",
    "# Confusion Matrix\n",
    "def CM_viz(y_test, y_pred, classes, name,\n",
    "               path_img_base = './images',nrows=1,ncols=1,size_text_legend=25,size_text_title=25,title=\"\",\n",
    "           size_text_xy_labels=25,size_text_xy_tick=25,\n",
    "          size_num_inter=25):\n",
    "    if not os.path.exists(path_img_base):\n",
    "        os.makedirs(path_img_base)\n",
    "    \n",
    "    if ncols==nrows and ncols==1:\n",
    "        nrows=1\n",
    "        ncols=1\n",
    "        #fig = plt.figure(figsize=(20*ncols,20*nrows))\n",
    "        conf = confusion_matrix(y_test, y_pred) \n",
    "        annot_kws={'fontsize':size_num_inter, 'verticalalignment':'center' } \n",
    "        ax = sns.heatmap(conf, annot=True, cbar=False, cmap='Blues',fmt = 'd',annot_kws= annot_kws, \n",
    "                                      xticklabels=np.unique(classes), yticklabels=np.unique(classes)) \n",
    "        #cbar = ax.collections[0].colorbar # use matplotlib.colorbar.Colorbar object\n",
    "        #cbar.ax.tick_params(labelsize=size_text_xy_tick) # here set the labelsize \n",
    "        ax.xaxis.set_tick_params(labelsize=size_text_xy_tick,rotation=90)\n",
    "        ax.yaxis.set_tick_params(labelsize=size_text_xy_tick,rotation=0)\n",
    "        ax.set_xlabel('Predicted Values',fontsize=size_text_xy_labels)\n",
    "        ax.set_ylabel('Actual Values',fontsize=size_text_xy_labels)\n",
    "        ax.set_title(title,fontsize=size_text_title)\n",
    "        #ax.figure.subplots_adjust(right=0.8)\n",
    "        #ax.figure.savefig(path_figures+\"/\"+name+\"_CM\"+\".pdf\", bbox_inches = \"tight\", format='pdf')\n",
    "    else:\n",
    "        conf = confusion_matrix(y_test, y_pred) \n",
    "        annot_kws={'fontsize':size_num_inter, 'verticalalignment':'center' }\n",
    "\n",
    "        ax = sns.heatmap(conf, annot=True, cbar=False, cmap='Blues',fmt = 'd',annot_kws= annot_kws, \n",
    "                                      xticklabels=np.unique(classes), yticklabels=np.unique(classes)) \n",
    "        #cbar = ax.collections[0].colorbar # use matplotlib.colorbar.Colorbar object\n",
    "        #cbar.ax.tick_params(labelsize=size_text_xy_tick) # here set the labelsize \n",
    "        ax.xaxis.set_tick_params(labelsize=size_text_xy_tick,rotation=90)\n",
    "        ax.yaxis.set_tick_params(labelsize=size_text_xy_tick,rotation=0)\n",
    "        ax.set_xlabel('Predicted Values',fontsize=size_text_xy_labels)\n",
    "        ax.set_ylabel('Actual Values',fontsize=size_text_xy_labels)\n",
    "        ax.set_title(title,fontsize=size_text_title)\n",
    "        \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ca44de",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_figures = \"../images\"\n",
    "if not os.path.exists(path_figures):\n",
    "    os.makedirs(path_figures)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7701b8df",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f11dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_folder_data = \"../DBs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09564db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDSAI\n",
    "path     = path_folder_data+'/IDSAI.csv'\n",
    "df_IDSAI = pd.read_csv(path)\n",
    "#Only once\n",
    "#df_IDSAI[\"tipo_ataque\"].replace({\n",
    "#                        \"dos-icmp_flood\": \"ICMP echo request Flood\", \n",
    "#                        \"dos-syn_rstflooding\": \"SYN/ACK and RST Flooding\",\n",
    "#                        \"dos-synflooding\": \"SYN/ACK Flooding\",\n",
    "#                        \"dos-synfloodingfaster\": \"SYN Flooding faster\",\n",
    "#                        \"mitm-arp_spoofing\": \"ARP spoofing\",                                                \n",
    "#                        \"ddos_mac\": \"DDoS MAC Flood\", \n",
    "#                        \"framentation_ip\": \"IP Fragmentation\",\n",
    "#                        \"fuerzabrutassh\": \"Brute Force SSH\",                        \n",
    "#                        \"scan_puerto_udp\": \"UDP port scan\",                        \n",
    "#                        \"tcpnull\": \"TCP Null\",\n",
    "#                        \"normal\": \"Normal\"\n",
    "#                        }, inplace=True)\n",
    "#df_IDSAI.to_csv('../DBs'+'/IDSAI.csv', index = False, header=True)\n",
    "#df_IDSAI=pd.read_csv('../DBs'+'/IDSAI.csv')\n",
    "df_IDSAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1419d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bot-IoT\n",
    "path     = path_folder_data+'/Bot-IoT.csv'\n",
    "df_BotIoT = pd.read_csv(path)\n",
    "df_BotIoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54169390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution in IDSAI\n",
    "df_IDSAI.groupby(\"tipo_ataque\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91caf406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution in Bot-IoT\n",
    "df_BotIoT.groupby(\"tipo_ataque\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ab87bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# column names\n",
    "print(\"Same columns in DBs: \",(df_BotIoT.columns.values == df_IDSAI.columns.values).all()) \n",
    "print(\"Number of columns: \",len(list(df_BotIoT.columns.values))) \n",
    "list(df_BotIoT.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0b4f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IDSAI\n",
    "IDSAIpath_folder_data = \"../DBs\"\n",
    "IDSAIpath = IDSAIpath_folder_data+'/IDSAI.csv'\n",
    "IDSAIdf=pd.read_csv(IDSAIpath)\n",
    "#IDSAIdf\n",
    "# Delete labels and redundant features\n",
    "IDSAIfeatures = IDSAIdf.copy()\n",
    "IDSAIfeatures = IDSAIfeatures.drop(['label', 'tipo_ataque','ip_src', 'ip_dst', 'port_src', 'port_dst', 'protocols'], axis=1) \n",
    "# Obtain labels\n",
    "IDSAIlabels = IDSAIdf.copy()\n",
    "IDSAIlabels = IDSAIlabels['label'].values \n",
    "\n",
    "# Load BotIoT\n",
    "BotIoTpath_folder_data = \"../DBs\"\n",
    "BotIoTpath = BotIoTpath_folder_data+'/Bot-Iot.csv'\n",
    "BotIoTdf=pd.read_csv(BotIoTpath)\n",
    "#BotIoTdf\n",
    "# Delete labels and redundant features\n",
    "BotIoTfeatures = BotIoTdf.copy()\n",
    "BotIoTfeatures = BotIoTfeatures.drop(['label', 'tipo_ataque','ip_src', 'ip_dst', 'port_src', 'port_dst', 'protocols'], axis=1) \n",
    "# Obtain labels\n",
    "BotIoTlabels = BotIoTdf.copy()\n",
    "BotIoTlabels = BotIoTlabels['label'].values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab28633",
   "metadata": {},
   "source": [
    "# IDSAI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a56a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete labels\n",
    "features = df_IDSAI.copy()\n",
    "features = features.drop(['label', 'tipo_ataque'], axis=1)\n",
    "features = features.drop(['ip_src', 'ip_dst', 'port_src', 'port_dst', 'protocols'], \n",
    "                         axis=1) # Features not recomended in literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5384534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b168492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraemos los labels\n",
    "labels = df_IDSAI.copy()\n",
    "\n",
    "labels_binary = labels['label'].values\n",
    "labels_multiclass = labels['tipo_ataque'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110acd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef52a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_multiclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f449d53",
   "metadata": {},
   "source": [
    "# Data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2724c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(aspect=\"equal\"))\n",
    "\n",
    "data = list(labels['tipo_ataque'].value_counts().values)\n",
    "names = labels['tipo_ataque'].value_counts().index\n",
    "\n",
    "color_palette_list = [\"#0EBFE9\", \"#60D394\", \"#FFD97D\", \"#C1F0F6\", \"#007ACD\", \"#EE6055\",\n",
    "                      \"#6DC36D\", \"#BBA9BB\", \"#E7D40A\", \"#E36B2C\", \"#C82A54\"]\n",
    "\n",
    "def func(pct, allvals):\n",
    "    absolute = int(pct/100.*np.sum(allvals))\n",
    "    return \"{:.0f}%\\n({:d})\".format(pct, absolute)\n",
    "\n",
    "wedges, texts, autotexts = ax.pie(data, autopct=lambda pct: func(pct, data),\n",
    "                                  textprops=dict(color=\"gray\"), colors=color_palette_list[0:],\n",
    "                                 pctdistance=1.17)\n",
    "\n",
    "ax.legend(wedges, names,\n",
    "          loc=\"center left\",\n",
    "          bbox_to_anchor=(1, 0, 0.5, 1),\n",
    "         fontsize=15)\n",
    "\n",
    "plt.setp(autotexts, size=15, weight=\"bold\", color=\"gray\")\n",
    "\n",
    "plt.subplots_adjust(right=0.7)\n",
    "plt.savefig(path_figures+\"/data_distribution.pdf\", bbox_inches = \"tight\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cd8409",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2102098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size_text_legend=35\n",
    "size_text_title=85\n",
    "size_text_xy_labels=35\n",
    "size_text_xy_tick=35\n",
    "size_num_inter=35\n",
    "\n",
    "nrows=1\n",
    "ncols=2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SMALL_SIZE = 35\n",
    "MEDIUM_SIZE = 45\n",
    "BIGGER_SIZE = 65\n",
    "\n",
    "plt.rc('font',   size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes',   titlesize=size_text_title)     # fontsize of the axes title\n",
    "plt.rc('axes',   labelsize=size_text_xy_labels)    # fontsize of the x and y labels\n",
    "plt.rc('xtick',  labelsize=size_text_xy_tick)    # fontsize of the tick labels\n",
    "plt.rc('ytick',  labelsize=size_text_xy_tick)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=size_text_legend)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "fig = plt.figure(figsize=(20*ncols,20*nrows))\n",
    "fig.subplots_adjust(hspace=0.35, wspace=0.6)\n",
    "\n",
    "#https://jakevdp.github.io/PythonDataScienceHandbook/04.08-multiple-subplots.html\n",
    "\n",
    "i=1\n",
    "ax = fig.add_subplot(nrows, ncols, i)\n",
    "###############################################SCENARIO 1\n",
    "X_train,X_test,y_train,y_test=train_test_split(features, labels_binary,\n",
    "                                               test_size=0.2,random_state=21, stratify=labels_binary)\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape) \n",
    "print(np.unique(y_train, return_counts=True))\n",
    "print(np.unique(y_test, return_counts=True)) \n",
    "\n",
    "model_name = \"Binary classification - Decision Tree\"\n",
    "model_selected = DecisionTreeClassifier(criterion='entropy', max_depth=20, random_state=32)\n",
    "model_selected.fit(X_train, y_train)\n",
    "\n",
    "feature_importances=pd.DataFrame({'features':features.columns,'feature_importance':model_selected.feature_importances_})\n",
    "print(feature_importances.sort_values('feature_importance',ascending=False))\n",
    "\n",
    "y_pred = model_selected.predict(X_test)\n",
    "acc_score=accuracy_score(y_test,y_pred) \n",
    "print('accuracy_score: {0:.4f}'.format(acc_score))\n",
    "\n",
    "y_pred_proba = model_selected.predict_proba(X_test)\n",
    "classes = np.unique([\"Intrusion\",\"Normal\"])\n",
    "\n",
    "title=\"A\"\n",
    "\n",
    "#feature_names=list(X_train.columns)\n",
    "viz = FeatureImportances(model_selected)#,topn=14)\n",
    "viz.fit(X_train, y_train)\n",
    "model_name = \"FI_S1\"\n",
    "viz.show(outpath=path_figures+\"/\"+model_name+\"_FI\"+\".pdf\")\n",
    "title=\"A\"\n",
    "viz.set_title(title)\n",
    "###############################################\n",
    "\n",
    "i=2\n",
    "ax = fig.add_subplot(nrows, ncols, i)\n",
    "###############################################SCENARIO 2\n",
    "X_train,X_test,y_train,y_test=train_test_split(features, labels_multiclass,\n",
    "                                               test_size=0.2,random_state=21, stratify=labels_multiclass)\n",
    "\n",
    "#le_labels = LabelEncoder()\n",
    "#y_train = le_labels.fit_transform(y_train) \n",
    "#y_test = le_labels.transform(y_test) \n",
    "\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape) \n",
    "print(np.unique(y_train, return_counts=True))\n",
    "print(np.unique(y_test, return_counts=True)) \n",
    "\n",
    "\n",
    "model_name = \"Multiclass classification - Decision Tree\"\n",
    "model_selected = DecisionTreeClassifier(max_depth=20, random_state=32)\n",
    "model_selected.fit(X_train, y_train)\n",
    "\n",
    "feature_importances=pd.DataFrame({'features':features.columns,'feature_importance':model_selected.feature_importances_})\n",
    "print(feature_importances.sort_values('feature_importance',ascending=False))\n",
    "\n",
    "y_pred = model_selected.predict(X_test)\n",
    "acc_score=accuracy_score(y_test,y_pred) \n",
    "print('accuracy_score: {0:.4f}'.format(acc_score))\n",
    "\n",
    "y_pred_proba = model_selected.predict_proba(X_test)\n",
    "classes = np.unique(y_test)\n",
    "\n",
    "#title=\"Confusion Matrix for {}\".format(model_name)\n",
    "title=\"D\"\n",
    "viz = FeatureImportances(model_selected)#,topn=14)\n",
    "viz.fit(X_train, y_train)\n",
    "model_name = \"FI_S2\"\n",
    "viz.show(outpath=path_figures+\"/\"+model_name+\"_FI\"+\".pdf\")\n",
    "title=\"B\"\n",
    "viz.set_title(title)\n",
    "\n",
    "###############################################\n",
    "\n",
    "model_name = \"Feature_importance\"\n",
    "fig.savefig(path_figures+\"/\"+model_name+\"_FI\"+\".pdf\", bbox_inches = \"tight\", format='pdf') \n",
    "#fig.savefig(path_figures+\"/\"+model_name+\"_CM\"+\".pdf\", format='pdf') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f74053",
   "metadata": {},
   "source": [
    "# Confusion Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84bf437",
   "metadata": {},
   "source": [
    "## Scenarios 1 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26144909",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_text_legend=80\n",
    "size_text_title=150\n",
    "size_text_xy_labels=80\n",
    "size_text_xy_tick=80\n",
    "size_num_inter=80\n",
    "\n",
    "nrows=1\n",
    "ncols=2\n",
    "\n",
    "fig = plt.figure(figsize=(20*ncols,20*nrows))\n",
    "fig.subplots_adjust(hspace=0.25, wspace=0.5)\n",
    "#https://jakevdp.github.io/PythonDataScienceHandbook/04.08-multiple-subplots.html\n",
    "\n",
    "i=1\n",
    "ax = fig.add_subplot(nrows, ncols, i)\n",
    "###############################################SCENARIO 1\n",
    "X_train,X_test,y_train,y_test=train_test_split(features, labels_binary,\n",
    "                                               test_size=0.2,random_state=21, stratify=labels_binary)\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape) \n",
    "print(np.unique(y_train, return_counts=True))\n",
    "print(np.unique(y_test, return_counts=True)) \n",
    "\n",
    "model_name = \"Binary classification - XGB - IDSAI dataset\"\n",
    "model_selected = XGBClassifier(eval_metric='mlogloss',n_jobs=-1, random_state=32)\n",
    "model_selected.fit(X_train, y_train)\n",
    "y_pred = model_selected.predict(X_test)\n",
    "acc_score=accuracy_score(y_test,y_pred) \n",
    "print('accuracy_score: {0:.4f}'.format(acc_score))\n",
    "\n",
    "y_pred_proba = model_selected.predict_proba(X_test)\n",
    "classes = np.unique([\"Intrusion\",\"Normal\"])\n",
    "\n",
    "#title=\"Confusion Matrix for {}\".format(model_name)\n",
    "title=\"A\"\n",
    "CM_viz(y_test, y_pred, classes, name=model_name, \n",
    "                            path_img_base = './images',nrows=nrows,ncols=ncols, \n",
    "                            size_text_legend=size_text_legend,size_text_title=size_text_title,title=title,\n",
    "       size_text_xy_labels=size_text_xy_labels,size_text_xy_tick=size_text_xy_tick,size_num_inter=size_num_inter)\n",
    "###############################################\n",
    "\n",
    "i=2\n",
    "ax = fig.add_subplot(nrows, ncols, i)\n",
    "###############################################SCENARIO 3\n",
    "X_train = IDSAIfeatures\n",
    "X_test = BotIoTfeatures\n",
    "y_train = IDSAIlabels\n",
    "y_test = BotIoTlabels\n",
    "\n",
    "model_name = \"Binary classification - XGB - Bot-IoT dataset\"\n",
    "model_selected = XGBClassifier(eval_metric='mlogloss',n_jobs=-1, random_state=32)\n",
    "model_selected.fit(X_train, y_train)\n",
    "y_pred = model_selected.predict(X_test)\n",
    "acc_score=accuracy_score(y_test,y_pred) \n",
    "print('accuracy_score: {0:.4f}'.format(acc_score))\n",
    "\n",
    "y_pred_proba = model_selected.predict_proba(X_test)\n",
    "classes = np.unique([\"Intrusion\",\"Normal\"])\n",
    "\n",
    "#title=\"Confusion Matrix for {}\".format(model_name)\n",
    "title=\"B\"\n",
    "CM_viz(y_test, y_pred, classes, name=model_name, \n",
    "                            path_img_base = './images',nrows=nrows,ncols=ncols, \n",
    "                            size_text_legend=size_text_legend,size_text_title=size_text_title,title=title,\n",
    "       size_text_xy_labels=size_text_xy_labels,size_text_xy_tick=size_text_xy_tick,size_num_inter=size_num_inter)\n",
    "\n",
    "###############################################\n",
    "\n",
    "model_name = \"Fig_CM_1_3\"\n",
    "fig.savefig(path_figures+\"/\"+model_name+\".pdf\", bbox_inches = \"tight\", format='pdf') \n",
    "#fig.savefig(path_figures+\"/\"+model_name+\"_CM\"+\".pdf\", format='pdf') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38c4c2a",
   "metadata": {},
   "source": [
    "## Scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e077527",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_text_legend=35\n",
    "size_text_title=85\n",
    "size_text_xy_labels=35\n",
    "size_text_xy_tick=35\n",
    "size_num_inter=33\n",
    "\n",
    "nrows=1\n",
    "ncols=1\n",
    "\n",
    "fig = plt.figure(figsize=(20*ncols,20*nrows))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.3)\n",
    "#https://jakevdp.github.io/PythonDataScienceHandbook/04.08-multiple-subplots.html\n",
    "\n",
    "i=1\n",
    "ax = fig.add_subplot(nrows, ncols, i)\n",
    "###############################################SCENARIO 2\n",
    "X_train,X_test,y_train,y_test=train_test_split(features, labels_multiclass,\n",
    "                                               test_size=0.2,random_state=21, stratify=labels_multiclass)\n",
    "\n",
    "#le_labels = LabelEncoder()\n",
    "#y_train = le_labels.fit_transform(y_train) \n",
    "#y_test = le_labels.transform(y_test) \n",
    "\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape) \n",
    "print(np.unique(y_train, return_counts=True))\n",
    "print(np.unique(y_test, return_counts=True)) \n",
    "\n",
    "#X_train,X_test,y_train,y_test=train_test_split(features, labels,\n",
    "#                                               test_size=0.2,random_state=21, stratify=labels)\n",
    "#print(X_train.shape,X_test.shape,y_train.shape,y_test.shape) \n",
    "#print(np.unique(y_train, return_counts=True))\n",
    "#print(np.unique(y_test, return_counts=True)) \n",
    "\n",
    "model_name = \"Multiclass classification - XGB - IDSAI dataset\"\n",
    "model_selected = XGBClassifier(eval_metric='mlogloss',n_jobs=-1, random_state=32)\n",
    "model_selected.fit(X_train, y_train)\n",
    "y_pred = model_selected.predict(X_test)\n",
    "acc_score=accuracy_score(y_test,y_pred) \n",
    "print('accuracy_score: {0:.4f}'.format(acc_score))\n",
    "\n",
    "y_pred_proba = model_selected.predict_proba(X_test)\n",
    "classes = np.unique(y_test)\n",
    "\n",
    "#title=\"Confusion Matrix for {}\".format(model_name)\n",
    "title=\"\"\n",
    "CM_viz(y_test, y_pred, classes, name=model_name, \n",
    "                            path_img_base = './images',nrows=nrows,ncols=ncols, \n",
    "                            size_text_legend=size_text_legend,size_text_title=size_text_title,title=title,\n",
    "       size_text_xy_labels=size_text_xy_labels,size_text_xy_tick=size_text_xy_tick,size_num_inter=size_num_inter)\n",
    "\n",
    "###############################################\n",
    "\n",
    "model_name = \"Fig_CM_2\"\n",
    "fig.savefig(path_figures+\"/\"+model_name+\".pdf\", bbox_inches = \"tight\", format='pdf') \n",
    "#fig.savefig(path_figures+\"/\"+model_name+\"_CM\"+\".pdf\", format='pdf') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
