{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a221bd65",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad446f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification Methods\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from yellowbrick.classifier import ClassificationReport \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#Tools\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from scipy.sparse import csr_matrix \n",
    "import string \n",
    "import time as tm\n",
    "import spacy \n",
    "import os\n",
    "\n",
    "# Hiperparameter tune\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Feature importance\n",
    "from yellowbrick.model_selection import FeatureImportances\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7e1df9",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521e558f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_metrics(X_train,X_test,y_train,y_test,CV=True):    \n",
    "    def metrics(model):\n",
    "        print(\"\\nHold-Out in process...\")\n",
    "        start_time = tm.time()\n",
    "        model.fit(X_train, y_train) \n",
    "        TIME = tm.time() - start_time \n",
    "        print(\"Time, Training: {0:.4f} [seconds]\".format(TIME))\n",
    "        start_time = tm.time()\n",
    "        y_pred = model.predict(X_test)\n",
    "        TIME = tm.time() - start_time \n",
    "        print(\"Time, Prediction: {0:.4f} [seconds]\".format(TIME))\n",
    "        \n",
    "        accuracy_s  = accuracy_score(y_test,y_pred) \n",
    "        print('accuracy_score: {0:.4f}'.format(accuracy_s))\n",
    "        f1_s        = f1_score(y_test,y_pred,average='weighted')\n",
    "        print('f1_score: {0:.4f}'.format(f1_s))\n",
    "        recall_s    = recall_score(y_test,y_pred,average='weighted')\n",
    "        print('recall_score: {0:.4f}'.format(recall_s))\n",
    "        precision_s = precision_score(y_test,y_pred,average='weighted')\n",
    "        print('precision_score: {0:.4f}'.format(precision_s))\n",
    "        \n",
    "        if type(list(np.unique(np.array(y_train)))[0]).__name__ == 'str': #If the classes are categorical with string names\n",
    "            le           = LabelEncoder() \n",
    "            le.fit(list(np.unique(np.array(y_train)))) \n",
    "            y_test_coded = le.transform(y_test) \n",
    "            y_pred_coded = le.transform(y_pred) \n",
    "            mse_s        = MSE(y_test_coded,y_pred_coded)\n",
    "            print('MSE: {0:.4f}'.format(mse_s))\n",
    "        else:\n",
    "            mse_s        = MSE(y_test,y_pred)\n",
    "            print('MSE: {0:.4f}'.format(mse_s))\n",
    "        \n",
    "        if len(list(np.unique(np.array(y_train)))) > 2: #For multiclass classification, more than 2 classes\n",
    "            y_pred_proba = model.predict_proba(X_test)[:]\n",
    "            roc_s        = roc_auc_score(y_test, y_pred_proba, multi_class='ovo', average='weighted')\n",
    "            print('ROC_AUC: {0:.4f}'.format(roc_s))            \n",
    "        else:\n",
    "            y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "            roc_s        = roc_auc_score(y_test, y_pred_proba, multi_class='ovo', average='weighted')\n",
    "            print('ROC_AUC: {0:.4f}'.format(roc_s))\n",
    "        \n",
    "        ck_s         = cohen_kappa_score(y_test,y_pred)\n",
    "        print('CK: {0:.4f}'.format(ck_s))\n",
    "        \n",
    "        if CV == True:\n",
    "            print('\\nCross-Validation in process...')\n",
    "            start_time = tm.time() \n",
    "            kfold = model_selection.KFold(n_splits=10)\n",
    "            y_CV = np.concatenate((y_train,y_test))\n",
    "            if \"GaussianNB\" in str(name) or \"LinearDiscriminantAnalysis\" in str(name) or \"QuadraticDiscriminantAnalysis\" in str(name):\n",
    "                X_CV = np.concatenate((X_train,X_test))\n",
    "                cv_results = np.array(model_selection.cross_val_score(model, X_CV, y_CV, cv=kfold, scoring='accuracy', n_jobs=-3))\n",
    "            else:\n",
    "                X_CV = np.concatenate((X_train.toarray(),X_test.toarray()))\n",
    "                X_CV = csr_matrix(X_CV)\n",
    "                cv_results = np.array(model_selection.cross_val_score(model, X_CV, y_CV, cv=kfold, scoring='accuracy', n_jobs=-3))\n",
    "\n",
    "            cv_results = cv_results[np.logical_not(np.isnan(cv_results))] \n",
    "            TIME = tm.time() - start_time \n",
    "            print(\"Time, CV: {0:.4f} [seconds]\".format(TIME))\n",
    "            print('CV: {0:.4f} {1:.4f}'.format(cv_results.mean(),cv_results.std()))\n",
    "\n",
    "    for name in classifiers:\n",
    "        print (\"---------------------------------------------------------------------------------\\n\") \n",
    "        print(str(name))\n",
    "        if \"GaussianNB\" in str(name) or \"LinearDiscriminantAnalysis\" in str(name) or \"QuadraticDiscriminantAnalysis\" in str(name):\n",
    "            X_train=csr_matrix(X_train) \n",
    "            X_test =csr_matrix(X_test) \n",
    "            X_train=X_train.toarray() \n",
    "            X_test=X_test.toarray() \n",
    "        else:\n",
    "            X_train=csr_matrix(X_train)\n",
    "            X_test=csr_matrix(X_test)\n",
    "            \n",
    "        metrics(name)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fb3778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "def CR_viz(x,y):\n",
    "    ax = plt.figure(figsize=(x,y)) \n",
    "    visualizer = ClassificationReport(model_selected, classes=classes, support=True,  \n",
    "                                      cmap='Blues', title=\"Classification Report - \"+model_name)\n",
    "    visualizer.fit(X_train, y_train)   \n",
    "    visualizer.score(X_test, y_test)      \n",
    "    visualizer.poof()\n",
    "    ax.show()\n",
    "    ax.savefig(path_figures+\"/\"+model_name+\"_CR\"+\".pdf\", bbox_inches = \"tight\") \n",
    "\n",
    "# Confusion Matrix\n",
    "def CM_viz(y_test, y_pred, classes, name,\n",
    "               path_img_base = './images',nrows=1,ncols=1,size_text_legend=25,size_text_title=25,title=\"\",\n",
    "           size_text_xy_labels=25,size_text_xy_tick=25,\n",
    "          size_num_inter=25):\n",
    "    if not os.path.exists(path_img_base):\n",
    "        os.makedirs(path_img_base)\n",
    "    \n",
    "    if ncols==nrows and ncols==1:\n",
    "        nrows=1\n",
    "        ncols=1\n",
    "        fig = plt.figure(figsize=(20*ncols,20*nrows))\n",
    "        conf = confusion_matrix(y_test, y_pred) \n",
    "        annot_kws={'fontsize':size_num_inter, 'verticalalignment':'center' } \n",
    "        ax = sns.heatmap(conf, annot=True, cbar=False, cmap='Blues',fmt = 'd',annot_kws= annot_kws, \n",
    "                                      xticklabels=np.unique(classes), yticklabels=np.unique(classes)) \n",
    "        #cbar = ax.collections[0].colorbar # use matplotlib.colorbar.Colorbar object\n",
    "        #cbar.ax.tick_params(labelsize=size_text_xy_tick) # here set the labelsize \n",
    "        ax.xaxis.set_tick_params(labelsize=size_text_xy_tick,rotation=90)\n",
    "        ax.yaxis.set_tick_params(labelsize=size_text_xy_tick,rotation=0)\n",
    "        ax.set_xlabel('Predicted Values',fontsize=size_text_xy_labels)\n",
    "        ax.set_ylabel('Actual Values',fontsize=size_text_xy_labels)\n",
    "        ax.set_title(title,fontsize=size_text_title)\n",
    "        ax.figure.subplots_adjust(right=0.8)\n",
    "        ax.figure.savefig(path_figures+\"/\"+name+\"_CM\"+\".pdf\", bbox_inches = \"tight\", format='pdf')\n",
    "    else:\n",
    "        conf = confusion_matrix(y_test, y_pred) \n",
    "        annot_kws={'fontsize':size_num_inter, 'verticalalignment':'center' }\n",
    "\n",
    "        ax = sns.heatmap(conf, annot=True, cbar=False, cmap='Blues',fmt = 'd',annot_kws= annot_kws, \n",
    "                                      xticklabels=np.unique(classes), yticklabels=np.unique(classes)) \n",
    "        #cbar = ax.collections[0].colorbar # use matplotlib.colorbar.Colorbar object\n",
    "        #cbar.ax.tick_params(labelsize=size_text_xy_tick) # here set the labelsize \n",
    "        ax.xaxis.set_tick_params(labelsize=size_text_xy_tick,rotation=90)\n",
    "        ax.yaxis.set_tick_params(labelsize=size_text_xy_tick,rotation=0)\n",
    "        ax.set_xlabel('Predicted Values',fontsize=size_text_xy_labels)\n",
    "        ax.set_ylabel('Actual Values',fontsize=size_text_xy_labels)\n",
    "        ax.set_title(title,fontsize=size_text_title)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ca44de",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_figures = \"../images\"\n",
    "if not os.path.exists(path_figures):\n",
    "    os.makedirs(path_figures)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7701b8df",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f11dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_folder_data = \"../DBs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09564db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDSAI\n",
    "path     = path_folder_data+'/IDSAI.csv'\n",
    "df_IDSAI = pd.read_csv(path)\n",
    "df_IDSAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1419d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bot-IoT\n",
    "path     = path_folder_data+'/Bot-IoT.csv'\n",
    "df_BotIoT = pd.read_csv(path)\n",
    "df_BotIoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54169390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution in IDSAI\n",
    "df_IDSAI.groupby(\"tipo_ataque\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91caf406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution in Bot-IoT\n",
    "df_BotIoT.groupby(\"tipo_ataque\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ab87bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names\n",
    "print(\"Same columns in DBs: \",(df_BotIoT.columns.values == df_IDSAI.columns.values).all()) \n",
    "print(\"Number of columns: \",len(list(df_BotIoT.columns.values))) \n",
    "list(df_BotIoT.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab28633",
   "metadata": {},
   "source": [
    "# IDSAI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a56a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete labels\n",
    "features = df_IDSAI.copy()\n",
    "features = features.drop(['label', 'tipo_ataque'], axis=1)\n",
    "features = features.drop(['ip_src', 'ip_dst', 'port_src', 'port_dst', 'protocols'], \n",
    "                         axis=1) # Features not recomended in literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5384534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b168492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraemos los labels\n",
    "labels = df_IDSAI.copy()\n",
    "\n",
    "labels_binary = labels['label'].values\n",
    "labels_multiclass = labels['tipo_ataque'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110acd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef52a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_multiclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df39018d",
   "metadata": {},
   "source": [
    "## Scenario 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea29cac3",
   "metadata": {},
   "source": [
    "### Inicial model exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e328404",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(features, labels_binary,\n",
    "                                               test_size=0.2,random_state=21, stratify=labels_binary)\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape) \n",
    "print(np.unique(y_train, return_counts=True))\n",
    "print(np.unique(y_test, return_counts=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60cec8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ML Models\n",
    "classifiers=[\n",
    "    DecisionTreeClassifier(),\n",
    "    ExtraTreesClassifier(n_jobs=-1), \n",
    "    RandomForestClassifier(n_jobs=-1),\n",
    "    GradientBoostingClassifier(),\n",
    "    XGBClassifier(eval_metric='mlogloss',n_jobs=-1),\n",
    "    GaussianNB(),    \n",
    "    LinearDiscriminantAnalysis(),\n",
    "    LogisticRegression(solver='liblinear',n_jobs=-1)\n",
    "    ] \n",
    "\n",
    "#Deploy aggregate metrics \n",
    "classifier_metrics(X_train,X_test,y_train,y_test,CV=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc69efb",
   "metadata": {},
   "source": [
    "### Hiperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3f2789",
   "metadata": {},
   "source": [
    "#### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546d13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to tune\n",
    "model = XGBClassifier(eval_metric='mlogloss',n_jobs=-1)\n",
    "\n",
    "# Hiperparameter values\n",
    "param_grid = {\n",
    "              \"min_child_weight\":[1, 5],\n",
    "              \"gamma\": [0.5, 1.5, 5],\n",
    "              \"subsample\":[0.75, 1],\n",
    "              \"colsample_bytree\":[0.75, 1],\n",
    "              \"max_depth\":[2, 6]\n",
    "             }\n",
    "\n",
    "# Grid\n",
    "grid = GridSearchCV(model,param_grid,cv=3,verbose=3)\n",
    "\n",
    "# Tuning\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "# Best model\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Predictions with best hiperparameters\n",
    "grid_predictions = grid.predict(X_test) \n",
    "\n",
    "# Metrics\n",
    "print(confusion_matrix(y_test,grid_predictions)) \n",
    "print(classification_report(y_test,grid_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9b3f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with hiperparameters using GridSearch \n",
    "model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.75,\n",
    "              enable_categorical=False, eval_metric='mlogloss', gamma=1.5,\n",
    "              gpu_id=-1, importance_type=None, interaction_constraints='',\n",
    "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
    "              min_child_weight=1, missing=np.nan, monotone_constraints='()',\n",
    "              n_estimators=100, n_jobs=-1, num_parallel_tree=1,\n",
    "              predictor='auto', random_state=0, reg_alpha=0, reg_lambda=1,\n",
    "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
    "              validate_parameters=1, verbosity=None)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a1f538",
   "metadata": {},
   "source": [
    "#### ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9551bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExtraTreesClassifier(n_jobs=-1).get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fadfaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to tune\n",
    "model = ExtraTreesClassifier(n_jobs=-1)\n",
    "\n",
    "# Hiperparameter values\n",
    "param_grid = {\n",
    "        'n_estimators': [100,150,200],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [10, 50, 80, None]\n",
    "    },\n",
    "\n",
    "# Grid\n",
    "grid = GridSearchCV(model,param_grid,cv=3,verbose=3)\n",
    "\n",
    "# Tuning\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "# Best model\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Predictions with best hiperparameters\n",
    "grid_predictions = grid.predict(X_test) \n",
    "\n",
    "# Metrics\n",
    "print(confusion_matrix(y_test,grid_predictions)) \n",
    "print(classification_report(y_test,grid_predictions)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18e2ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with hiperparameters using GridSearch \n",
    "model = ExtraTreesClassifier(criterion='entropy', max_depth=50, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355a8738",
   "metadata": {},
   "source": [
    "#### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2c3a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTreeClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e33997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to tune\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Hiperparameter values\n",
    "param_grid = {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [10, 20, 30, 40, 50, 100, 150, 200, None],\n",
    "        'random_state':[32,64]\n",
    "    },\n",
    "\n",
    "# Grid\n",
    "grid = GridSearchCV(model,param_grid,cv=3,verbose=3)\n",
    "\n",
    "# Tuning\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "# Best model\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Predictions with best hiperparameters\n",
    "grid_predictions = grid.predict(X_test) \n",
    "\n",
    "# Metrics\n",
    "print(confusion_matrix(y_test,grid_predictions)) \n",
    "print(classification_report(y_test,grid_predictions)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d1c35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with hiperparameters using GridSearch \n",
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=20, random_state=32)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8d4db8",
   "metadata": {},
   "source": [
    "#### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6796473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier(n_jobs=-1).get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9548238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to tune\n",
    "model = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "# Hiperparameter values\n",
    "param_grid = {\n",
    "        'n_estimators': [60,100,120,150],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [10, 20, 40, None],\n",
    "        'random_state':[32, 64]\n",
    "    },\n",
    "\n",
    "# Grid\n",
    "grid = GridSearchCV(model,param_grid,cv=3,verbose=3)\n",
    "\n",
    "# Tuning\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "# Best model\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Predictions with best hiperparameters\n",
    "grid_predictions = grid.predict(X_test) \n",
    "\n",
    "# Metrics\n",
    "print(confusion_matrix(y_test,grid_predictions)) \n",
    "print(classification_report(y_test,grid_predictions)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d6e210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with hiperparameters using GridSearch \n",
    "model = RandomForestClassifier(criterion='entropy', max_depth=20, n_estimators=150,\n",
    "                       n_jobs=-1, random_state=32)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7361f5",
   "metadata": {},
   "source": [
    "#### GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17dde1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GradientBoostingClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01576804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to tune\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "# Hiperparameter values\n",
    "param_grid = {\n",
    "        \"n_estimators\":[50,100,150],\n",
    "        \"max_depth\":[1,3,5,9],\n",
    "        'random_state':[32, 64]\n",
    "    },\n",
    "\n",
    "# Grid\n",
    "grid = GridSearchCV(model,param_grid,cv=3,verbose=3)\n",
    "\n",
    "# Tuning\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "# Best model\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Predictions with best hiperparameters\n",
    "grid_predictions = grid.predict(X_test) \n",
    "\n",
    "# Metrics\n",
    "print(confusion_matrix(y_test,grid_predictions)) \n",
    "print(classification_report(y_test,grid_predictions)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020bd2ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model with hiperparameters using GridSearch \n",
    "model = GradientBoostingClassifier(max_depth=9, random_state=64)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaa0645",
   "metadata": {},
   "source": [
    "### Best models for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d765cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ML Models\n",
    "classifiers=[\n",
    "    XGBClassifier(eval_metric='mlogloss',n_jobs=-1, random_state=32),\n",
    "    ExtraTreesClassifier(criterion='entropy', max_depth=50, n_jobs=-1, random_state=32),\n",
    "    DecisionTreeClassifier(criterion='entropy', max_depth=20, random_state=32),\n",
    "    RandomForestClassifier(criterion='entropy', max_depth=20, n_estimators=150,n_jobs=-1, random_state=32),\n",
    "    GradientBoostingClassifier(max_depth=9, random_state=64)\n",
    "    ] \n",
    "\n",
    "#Deploy aggregate metrics \n",
    "classifier_metrics(X_train,X_test,y_train,y_test,CV=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571e3542",
   "metadata": {},
   "source": [
    "### Feature importance binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78ca317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with hiperparameters using GridSearch \n",
    "model = XGBClassifier(eval_metric='mlogloss',n_jobs=-1, random_state=32)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy: \", model.score(X_test, y_test))\n",
    "\n",
    "# Mostrar la importancia de características\n",
    "viz = FeatureImportances(model, topn=19)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f5cf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with hiperparameters using GridSearch \n",
    "model = ExtraTreesClassifier(criterion='entropy', max_depth=50, n_jobs=-1, random_state=32)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy: \", model.score(X_test, y_test))\n",
    "\n",
    "# Mostrar la importancia de características\n",
    "viz = FeatureImportances(model, topn=19)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba66b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with hiperparameters using GridSearch \n",
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=20, random_state=32)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy: \", model.score(X_test, y_test))\n",
    "\n",
    "# Mostrar la importancia de características\n",
    "viz = FeatureImportances(model, topn=19)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5026cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with hiperparameters using GridSearch \n",
    "model = RandomForestClassifier(criterion='entropy', max_depth=20, n_estimators=150,n_jobs=-1, random_state=32)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy: \", model.score(X_test, y_test))\n",
    "\n",
    "# Mostrar la importancia de características\n",
    "viz = FeatureImportances(model, topn=19)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa72686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with hiperparameters using GridSearch \n",
    "model = GradientBoostingClassifier(max_depth=9, random_state=64)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy: \", model.score(X_test, y_test))\n",
    "\n",
    "# Mostrar la importancia de características\n",
    "viz = FeatureImportances(model, topn=19)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfb558f",
   "metadata": {},
   "source": [
    "## Scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07713217",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(features, labels_multiclass,\n",
    "                                               test_size=0.2,random_state=21, stratify=labels_multiclass)\n",
    "\n",
    "le_labels = LabelEncoder()\n",
    "y_train = le_labels.fit_transform(y_train) \n",
    "y_test = le_labels.transform(y_test) \n",
    "\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape) \n",
    "print(np.unique(y_train, return_counts=True))\n",
    "print(np.unique(y_test, return_counts=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efef7a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ML Models\n",
    "classifiers=[\n",
    "    DecisionTreeClassifier(),\n",
    "    ExtraTreesClassifier(n_jobs=-1), \n",
    "    RandomForestClassifier(n_jobs=-1),\n",
    "    GradientBoostingClassifier(),\n",
    "    XGBClassifier(eval_metric='mlogloss',n_jobs=-1),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    LogisticRegression(solver='liblinear',n_jobs=-1)\n",
    "    ] \n",
    "\n",
    "#Deploy aggregate metrics \n",
    "classifier_metrics(X_train,X_test,y_train,y_test,CV=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f280aa",
   "metadata": {},
   "source": [
    "### Hiperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3154325",
   "metadata": {},
   "source": [
    "#### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ef2eac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model to tune\n",
    "model = XGBClassifier(eval_metric='mlogloss',n_jobs=-1)\n",
    "\n",
    "# Hiperparameter values\n",
    "param_grid = {\n",
    "              \"min_child_weight\":[1, 5],\n",
    "              \"gamma\": [0.5, 1.5, 5],\n",
    "              \"colsample_bytree\":[0.75, 1],\n",
    "              \"max_depth\":[2, 6]\n",
    "             }\n",
    "\n",
    "# Grid\n",
    "grid = GridSearchCV(model,param_grid,cv=3,verbose=3)\n",
    "\n",
    "# Tuning\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "# Best model\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Predictions with best hiperparameters\n",
    "grid_predictions = grid.predict(X_test) \n",
    "\n",
    "# Metrics\n",
    "print(confusion_matrix(y_test,grid_predictions)) \n",
    "print(classification_report(y_test,grid_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7598d0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with hiperparameters using GridSearch \n",
    "model = XGBClassifier(eval_metric='mlogloss',n_jobs=-1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8636fb",
   "metadata": {},
   "source": [
    "#### ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7366e9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExtraTreesClassifier(n_jobs=-1).get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d3748d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model to tune\n",
    "model = ExtraTreesClassifier(n_jobs=-1)\n",
    "\n",
    "# Hiperparameter values\n",
    "param_grid = {\n",
    "        'n_estimators': [100,150,200],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [10, 50, 80, None],\n",
    "        'random_state':[32, 64]\n",
    "    }\n",
    "\n",
    "# Grid\n",
    "grid = GridSearchCV(model,param_grid,cv=3,verbose=3)\n",
    "\n",
    "# Tuning\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "# Best model\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Predictions with best hiperparameters\n",
    "grid_predictions = grid.predict(X_test) \n",
    "\n",
    "# Metrics\n",
    "print(confusion_matrix(y_test,grid_predictions)) \n",
    "print(classification_report(y_test,grid_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe6a651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with hiperparameters using GridSearch \n",
    "model = ExtraTreesClassifier(max_depth=50, n_estimators=150, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55401a2a",
   "metadata": {},
   "source": [
    "#### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f17226",
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTreeClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8896a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to tune\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Hiperparameter values\n",
    "param_grid = {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [10, 20, 30, 40, 50, 100, 150, 200, None],\n",
    "        'random_state':[32,64]\n",
    "    }\n",
    "\n",
    "# Grid\n",
    "grid = GridSearchCV(model,param_grid,cv=3,verbose=3)\n",
    "\n",
    "# Tuning\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "# Best model\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Predictions with best hiperparameters\n",
    "grid_predictions = grid.predict(X_test) \n",
    "\n",
    "# Metrics\n",
    "print(confusion_matrix(y_test,grid_predictions)) \n",
    "print(classification_report(y_test,grid_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e671c53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with hiperparameters using GridSearch \n",
    "model = DecisionTreeClassifier(max_depth=20, random_state=32)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a98ec8",
   "metadata": {},
   "source": [
    "#### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2a8eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier(n_jobs=-1).get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e196f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to tune\n",
    "model = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "# Hiperparameter values\n",
    "param_grid = {\n",
    "        'n_estimators': [60,100,120,150],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [10, 20, 40, None],\n",
    "        'random_state':[32, 64]\n",
    "    }\n",
    "\n",
    "# Grid\n",
    "grid = GridSearchCV(model,param_grid,cv=3,verbose=3)\n",
    "\n",
    "# Tuning\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "# Best model\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Predictions with best hiperparameters\n",
    "grid_predictions = grid.predict(X_test) \n",
    "\n",
    "# Metrics\n",
    "print(confusion_matrix(y_test,grid_predictions)) \n",
    "print(classification_report(y_test,grid_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d1623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with hiperparameters using GridSearch \n",
    "model = RandomForestClassifier(max_depth=20, n_estimators=120, n_jobs=-1, random_state=64)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b324e5",
   "metadata": {},
   "source": [
    "#### GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb98640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GradientBoostingClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc1db23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model to tune\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "# Hiperparameter values\n",
    "param_grid = {\n",
    "        \"n_estimators\":[50,100,150],\n",
    "        \"max_depth\":[1,3,5,9],\n",
    "        'random_state':[32, 64]\n",
    "    }\n",
    "\n",
    "# Grid\n",
    "grid = GridSearchCV(model,param_grid,cv=3,verbose=3)\n",
    "\n",
    "# Tuning\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "# Best model\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Predictions with best hiperparameters\n",
    "grid_predictions = grid.predict(X_test) \n",
    "\n",
    "# Metrics\n",
    "print(confusion_matrix(y_test,grid_predictions)) \n",
    "print(classification_report(y_test,grid_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208b4f38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model with hiperparameters using GridSearch \n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy: \", model.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ced05f",
   "metadata": {},
   "source": [
    "### Best models for multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738b457f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ML Models\n",
    "classifiers=[\n",
    "        XGBClassifier(eval_metric='mlogloss',n_jobs=-1),\n",
    "        ExtraTreesClassifier(max_depth=50, n_estimators=150, n_jobs=-1),\n",
    "        DecisionTreeClassifier(max_depth=20, random_state=32),\n",
    "        RandomForestClassifier(max_depth=20, n_estimators=120, n_jobs=-1, random_state=64),\n",
    "        GradientBoostingClassifier()\n",
    "    ] \n",
    "\n",
    "#Deploy aggregate metrics \n",
    "classifier_metrics(X_train,X_test,y_train,y_test,CV=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3780d11",
   "metadata": {},
   "source": [
    "### Feature importance multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928439f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with hiperparameters using GridSearch \n",
    "model = XGBClassifier(eval_metric='mlogloss',n_jobs=-1, random_state=32)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy: \", model.score(X_test, y_test))\n",
    "\n",
    "# Mostrar la importancia de características\n",
    "viz = FeatureImportances(model, topn=19)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe1b34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with hiperparameters using GridSearch \n",
    "model = ExtraTreesClassifier(max_depth=50, n_estimators=150, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy: \", model.score(X_test, y_test))\n",
    "\n",
    "# Mostrar la importancia de características\n",
    "viz = FeatureImportances(model, topn=19)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d1e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with hiperparameters using GridSearch \n",
    "model = DecisionTreeClassifier(max_depth=20, random_state=32)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy: \", model.score(X_test, y_test))\n",
    "\n",
    "# Mostrar la importancia de características\n",
    "viz = FeatureImportances(model, topn=19)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596eafd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with hiperparameters using GridSearch \n",
    "model = RandomForestClassifier(max_depth=20, n_estimators=120, n_jobs=-1, random_state=64)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy: \", model.score(X_test, y_test))\n",
    "\n",
    "# Mostrar la importancia de características\n",
    "viz = FeatureImportances(model, topn=19)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f0fd62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model with hiperparameters using GridSearch \n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy: \", model.score(X_test, y_test))\n",
    "\n",
    "# Mostrar la importancia de características\n",
    "viz = FeatureImportances(model, topn=19)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb7cb10",
   "metadata": {},
   "source": [
    "# External validation using Bot-IoT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1486b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IDSAI\n",
    "IDSAIpath_folder_data = \"../DBs\"\n",
    "IDSAIpath = IDSAIpath_folder_data+'/IDSAI.csv'\n",
    "IDSAIdf=pd.read_csv(IDSAIpath)\n",
    "#IDSAIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d2743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete labels and redundant features\n",
    "IDSAIfeatures = IDSAIdf.copy()\n",
    "IDSAIfeatures = IDSAIfeatures.drop(['label', 'tipo_ataque','ip_src', 'ip_dst', 'port_src', 'port_dst', 'protocols'], axis=1) \n",
    "# Obtain labels\n",
    "IDSAIlabels = IDSAIdf.copy()\n",
    "IDSAIlabels = IDSAIlabels['label'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3a3eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BotIoT\n",
    "BotIoTpath_folder_data = \"../DBs\"\n",
    "BotIoTpath = BotIoTpath_folder_data+'/Bot-Iot.csv'\n",
    "BotIoTdf=pd.read_csv(BotIoTpath)\n",
    "#BotIoTdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c605ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete labels and redundant features\n",
    "BotIoTfeatures = BotIoTdf.copy()\n",
    "BotIoTfeatures = BotIoTfeatures.drop(['label', 'tipo_ataque','ip_src', 'ip_dst', 'port_src', 'port_dst', 'protocols'], axis=1) \n",
    "# Obtain labels\n",
    "BotIoTlabels = BotIoTdf.copy()\n",
    "BotIoTlabels = BotIoTlabels['label'].values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a58057",
   "metadata": {},
   "source": [
    "## Scenario 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690dea17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Entrenamiento en IDSIA predicción en Bot-IoT\n",
    "\n",
    "#ML Models\n",
    "classifiers=[\n",
    "    XGBClassifier(eval_metric='mlogloss',n_jobs=-1, random_state=32),\n",
    "    ExtraTreesClassifier(criterion='entropy', max_depth=50, n_jobs=-1, random_state=32),\n",
    "    DecisionTreeClassifier(random_state=32),\n",
    "    RandomForestClassifier(criterion='entropy', max_depth=20, n_estimators=150,n_jobs=-1, random_state=32),\n",
    "    GradientBoostingClassifier()\n",
    "    ] \n",
    "\n",
    "#Deploy aggregate metrics \n",
    "classifier_metrics(IDSAIfeatures,BotIoTfeatures,IDSAIlabels,BotIoTlabels,CV=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333ac43b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
